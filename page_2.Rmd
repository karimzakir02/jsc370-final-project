---
title: "Methods and Results"
output: 
    html_document:
        toc: TRUE
        toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library("tidyverse")
library("knitr")
library("tidytext")
library("lubridate")
library("stargazer")
library("wordcloud")
library("kableExtra")
```

```{r, include=FALSE}
dat <- read_csv("data/processed_data.csv")
sw_regex <- paste0(" ", paste0(stop_words$word ,collapse = " | ")) %>% paste0(" s")

bing <- get_sentiments("bing")
```

```{r}
dem_articles <- dat %>% 
  filter(president == "dem")

republican_articles <- dat %>% 
  filter(president == "rep")
```

## Showcasing plots {.tabset}

### 2012-2016 Word Cloud

```{r}
top50_common_dem <- dem_articles[, 1, drop = FALSE] %>% 
  unnest_tokens(word, title) %>% 
  anti_join(stop_words, by = c("word" = "word")) %>% 
  filter(word != "0091") %>% 
  count(word, sort = TRUE) %>% 
  top_n(50, n)
wordcloud(top50_common_dem$word, top50_common_dem$n)
```

### 2016-2020 Word Cloud

```{r}
top50_common_rep <- republican_articles[, 1, drop = FALSE] %>% 
  unnest_tokens(word, title) %>% 
  anti_join(stop_words, by = c("word" = "word")) %>% 
  filter(word != "0091") %>% 
  count(word, sort = TRUE) %>% 
  top_n(50, n)
wordcloud(top50_common_rep$word, top50_common_rep$n)
```

## Scraping the Data

## Looking Closely at the data

## Results